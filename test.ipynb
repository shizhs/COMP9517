{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import random\n",
    "# import warnings\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# from itertools import chain\n",
    "# from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "# from skimage.transform import resize\n",
    "# from skimage.morphology import label\n",
    "# import cv2\n",
    "# from keras.models import Model, load_model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers.core import Dropout, Lambda\n",
    "# from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "# from keras.layers.pooling import MaxPooling2D\n",
    "# from keras.layers.merge import concatenate\n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# from keras import backend as K\n",
    "# import re\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from scipy import ndimage as ndi\n",
    "# from skimage.morphology import watershed\n",
    "# from skimage.feature import peak_local_max\n",
    "# from sklearn.cluster import MeanShift\n",
    "# import cv2\n",
    "\n",
    "# # Set some parameters\n",
    "# IMG_WIDTH = 512\n",
    "# IMG_HEIGHT = 512\n",
    "# IMG_CHANNELS = 3\n",
    "# TRAIN_PATH = 'DIC-C2DH-HeLa/01/'\n",
    "# TEST_PATH = 'COMP9517 20T2 Group Project Image Sequences/DIC-C2DH-HeLa/Sequence 3/'\n",
    "\n",
    "# warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "# seed = 42\n",
    "# random.seed = seed\n",
    "# np.random.seed = seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get train and test IDs\n",
    "# train_ids = next(os.walk(TRAIN_PATH))[2]\n",
    "# test_ids = next(os.walk(TEST_PATH))[2]\n",
    "# print(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img=cv2.imread('DIC-C2DH-HeLa/01_ST/SEG/man_seg000.tif', -1)\n",
    "# plt.imshow(img)\n",
    "\n",
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH,3), dtype=np.uint8)\n",
    "# Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH,1), dtype=np.bool)\n",
    "# print('Getting and resizing train images and masks ... ')\n",
    "# sys.stdout.flush()\n",
    "# for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "#     path = TRAIN_PATH\n",
    "#     img = cv2.imread(path+id_)\n",
    "# #     img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "#     X_train[n] = img\n",
    "#     mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "#     num=''.join(re.findall(r'\\d+', id_))\n",
    "#     mask_ = cv2.imread('DIC-C2DH-HeLa/01_ST/SEG/man_seg'+ num+'.tif', -1)\n",
    "#     mask_ = cv2.resize(mask_, (IMG_HEIGHT, IMG_WIDTH))\n",
    "#     mask_=mask_[:,:,np.newaxis]\n",
    "#     mask = np.maximum(mask, mask_)\n",
    "# # for mask_file in next(os.walk('DIC-C2DH-HeLa/01_ST/SEG/'))[2]:\n",
    "# #     mask_ = cv2.imread('DIC-C2DH-HeLa/01_ST/SEG/'+ mask_file, -1)\n",
    "# # #     mask_ = cv2.cvtColor(mask_, cv2.COLOR_BGR2GRAY)\n",
    "# #     mask_ = cv2.resize(mask_, (IMG_HEIGHT, IMG_WIDTH))\n",
    "# #     mask = np.maximum(mask, mask_)\n",
    "#     Y_train[n] = mask\n",
    "\n",
    "# # Get and resize test images\n",
    "# X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH,3), dtype=np.uint8)\n",
    "# sizes_test = []\n",
    "# print('Getting and resizing test images ... ')\n",
    "# sys.stdout.flush()\n",
    "# for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "#     path = TEST_PATH\n",
    "#     img = cv2.imread(path+ id_)\n",
    "# #     img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#     sizes_test.append([img.shape[0], img.shape[1]])\n",
    "#     img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "#     X_test[n] = img\n",
    "\n",
    "# print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if training data looks all right\n",
    "# ix = random.randint(0, len(train_ids))\n",
    "# imshow(X_train[ix])\n",
    "# plt.show()\n",
    "# # imshow(np.squeeze(Y_train[1]))\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define IoU metric\n",
    "# def mean_iou(y_true, y_pred):\n",
    "#     prec = [] \n",
    "#     for t in np.arange(0.5, 1.0, 0.05):\n",
    "#         y_pred_ = tf.compat.v1.to_int32(y_pred > t)\n",
    "#         score, up_opt = tf.compat.v1.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "# #         tf.compat.v1.Session().run(tf.compat.v1.local_variables_initializer())\n",
    "#         with tf.control_dependencies([up_opt]):\n",
    "#             score = tf.identity(score)\n",
    "#         prec.append(score)\n",
    "#     return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "# s = Lambda(lambda x: x / 255) (inputs)\n",
    "\n",
    "# c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "# c1 = Dropout(0.1) (c1)\n",
    "# c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "# p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "# c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "# c2 = Dropout(0.1) (c2)\n",
    "# c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "# p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "# c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "# c3 = Dropout(0.2) (c3)\n",
    "# c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "# p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "# c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "# c4 = Dropout(0.2) (c4)\n",
    "# c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "# p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "# c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "# c5 = Dropout(0.3) (c5)\n",
    "# c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "# u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "# u6 = concatenate([u6, c4])\n",
    "# c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "# c6 = Dropout(0.2) (c6)\n",
    "# c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "# u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "# u7 = concatenate([u7, c3])\n",
    "# c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "# c7 = Dropout(0.2) (c7)\n",
    "# c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "# u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "# u8 = concatenate([u8, c2])\n",
    "# c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "# c8 = Dropout(0.1) (c8)\n",
    "# c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "# u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "# u9 = concatenate([u9, c1], axis=3)\n",
    "# c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "# c9 = Dropout(0.1) (c9)\n",
    "# c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "# outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "# model = Model(inputs=[inputs], outputs=[outputs])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.MeanIoU(num_classes=2)])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "# checkpointer = ModelCheckpoint('model-dsbowl2018-1.h5', verbose=1, save_best_only=True)\n",
    "# results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n",
    "#                     callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred=model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(pred[2].reshape(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def perform_watershed(image):\n",
    "#     distance = ndi.distance_transform_edt(image)\n",
    "#     peak = peak_local_max(distance,indices=False, labels=image)\n",
    "#     markers = ndi.label(peak)[0]\n",
    "#     ws_labels = watershed(-distance, markers, mask=image)\n",
    "#     return ws_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(ws_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "import cv2\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import re\n",
    "import tensorflow as tf\n",
    "# Set some parameters\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "IMG_CHANNELS = 1\n",
    "TRAIN_PATH = 'DIC-C2DH-HeLa/01/'\n",
    "TEST_PATH = 'COMP9517 20T2 Group Project Image Sequences/DIC-C2DH-HeLa/Sequence 3/'\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "\n",
    "\n",
    "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = Lambda(lambda x: x / 255) (inputs)\n",
    "#     inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model=Model([inputs], [conv10])\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 0.01), loss = \"binary_crossentropy\", metrics = ['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t007.tif', 't013.tif', 't012.tif', 't006.tif', 't010.tif', 't004.tif', 't038.tif', 't039.tif', 't005.tif', 't011.tif', 't029.tif', 't015.tif', 't001.tif', 't000.tif', 't014.tif', 't028.tif', 't002.tif', 't016.tif', 't017.tif', 't003.tif', 't064.tif', 't070.tif', 't058.tif', 't059.tif', 't071.tif', 't065.tif', 't073.tif', 't067.tif', 't066.tif', 't072.tif', 't076.tif', 't062.tif', 't063.tif', 't077.tif', 't049.tif', 't061.tif', 't075.tif', 't074.tif', 't060.tif', 't048.tif', 't045.tif', 't051.tif', 't079.tif', 't078.tif', 't050.tif', 't044.tif', 't052.tif', 't046.tif', 't047.tif', 't053.tif', 't080.tif', 't057.tif', 't043.tif', 't042.tif', 't056.tif', 't081.tif', 't083.tif', 't068.tif', 't040.tif', 't054.tif', 't055.tif', 't041.tif', 't069.tif', 't082.tif', 't026.tif', 't032.tif', 't033.tif', 't027.tif', 't031.tif', 't025.tif', 't019.tif', 't018.tif', 't024.tif', 't030.tif', 't008.tif', 't034.tif', 't020.tif', 't021.tif', 't035.tif', 't009.tif', 't023.tif', 't037.tif', 't036.tif', 't022.tif']\n",
      "Getting and resizing train images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 264.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting and resizing test images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 115/115 [00:00<00:00, 433.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get train and test IDs\n",
    "train_ids = next(os.walk(TRAIN_PATH))[2]\n",
    "test_ids = next(os.walk(TEST_PATH))[2]\n",
    "print(train_ids)\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH,IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH,1), dtype=np.bool)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH\n",
    "    img = cv2.imread(path+id_,0)\n",
    "#     img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    img=img[:,:,np.newaxis]\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool)\n",
    "    num=''.join(re.findall(r'\\d+', id_))\n",
    "    mask_ = cv2.imread('DIC-C2DH-HeLa/01_ST/SEG/man_seg'+ num+'.tif', -1)\n",
    "    mask_ = cv2.resize(mask_, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    mask_[mask_ > 0.5] = 1\n",
    "    mask_[mask_ <= 0.5] = 0\n",
    "    mask_=mask_[:,:,np.newaxis]\n",
    "#     mask = np.maximum(mask, mask_)\n",
    "# for mask_file in next(os.walk('DIC-C2DH-HeLa/01_ST/SEG/'))[2]:\n",
    "#     mask_ = cv2.imread('DIC-C2DH-HeLa/01_ST/SEG/'+ mask_file, -1)\n",
    "# #     mask_ = cv2.cvtColor(mask_, cv2.COLOR_BGR2GRAY)\n",
    "#     mask_ = cv2.resize(mask_, (IMG_HEIGHT, IMG_WIDTH))\n",
    "#     mask = np.maximum(mask, mask_)\n",
    "    Y_train[n] = mask_\n",
    "\n",
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH,1), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH\n",
    "    img = cv2.imread(path+ id_, 0)\n",
    "#     img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    img=img[:,:,np.newaxis]\n",
    "    X_test[n] = img\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 256, 256, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 256, 256, 64) 640         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 128, 128, 64) 0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 128, 128, 128 73856       max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 128, 128, 128 147584      conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 64, 64, 128)  0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 64, 64, 256)  295168      max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 32, 32, 256)  0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 32, 32, 512)  1180160     max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 512)  0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 512)  0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 1024) 4719616     max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16, 16, 1024) 0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling2D) (None, 32, 32, 1024) 0           dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 1024) 0           dropout_6[0][0]                  \n",
      "                                                                 conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling2D) (None, 64, 64, 512)  0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64, 64, 512)  0           conv2d_74[0][0]                  \n",
      "                                                                 conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling2D) (None, 128, 128, 256 0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 128, 128, 256 0           conv2d_72[0][0]                  \n",
      "                                                                 conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 128, 128, 128 295040      concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 128, 128, 128 147584      conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling2D) (None, 256, 256, 128 0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 256, 256, 128 0           conv2d_70[0][0]                  \n",
      "                                                                 conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 256, 256, 1)  65          conv2d_90[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,030,593\n",
      "Trainable params: 31,030,593\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.0211 - accuracy: 0.4788 \n",
      "Epoch 00001: val_loss improved from inf to 6.81786, saving model to unet_membrane.hdf5\n",
      "5/5 [==============================] - 53s 11s/step - loss: 8.0211 - accuracy: 0.4788 - val_loss: 6.8179 - val_accuracy: 0.5580\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.0237 - accuracy: 0.4798 \n",
      "Epoch 00002: val_loss did not improve from 6.81786\n",
      "5/5 [==============================] - 52s 10s/step - loss: 8.0237 - accuracy: 0.4798 - val_loss: 6.8179 - val_accuracy: 0.5580\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.0237 - accuracy: 0.4798 \n",
      "Epoch 00003: val_loss did not improve from 6.81786\n",
      "5/5 [==============================] - 53s 11s/step - loss: 8.0237 - accuracy: 0.4798 - val_loss: 6.8179 - val_accuracy: 0.5580\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.0237 - accuracy: 0.4798 \n",
      "Epoch 00004: val_loss did not improve from 6.81786\n",
      "5/5 [==============================] - 54s 11s/step - loss: 8.0237 - accuracy: 0.4798 - val_loss: 6.8179 - val_accuracy: 0.5580\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.0237 - accuracy: 0.4798 \n",
      "Epoch 00005: val_loss did not improve from 6.81786\n",
      "5/5 [==============================] - 54s 11s/step - loss: 8.0237 - accuracy: 0.4798 - val_loss: 6.8179 - val_accuracy: 0.5580\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - ETA: 0s - loss: 8.0237 - accuracy: 0.4798 \n",
      "Epoch 00006: val_loss did not improve from 6.81786\n",
      "5/5 [==============================] - 53s 11s/step - loss: 8.0237 - accuracy: 0.4798 - val_loss: 6.8179 - val_accuracy: 0.5580\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
    "checkpointer = ModelCheckpoint('unet_membrane.hdf5', verbose=1, save_best_only=True)\n",
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=16, epochs=50, \n",
    "                    callbacks=[earlystopper, checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 17s 4s/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff999575d50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred[2].reshape(IMG_HEIGHT, IMG_WIDTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
